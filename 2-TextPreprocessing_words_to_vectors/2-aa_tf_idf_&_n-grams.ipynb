{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF and N-Grams for Text Representation\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this notebook, we explore two key techniques for text representation:\n",
    "\n",
    "1. **TF-IDF (Term Frequency-Inverse Document Frequency)**: A technique to weigh the importance of a word in a document relative to its occurrence across the entire corpus.\n",
    "2. **N-Grams**: A method to capture sequences of words (such as bigrams and trigrams) to provide context-aware text representations.\n",
    "\n",
    "These methods are essential for improving the performance of text classification, clustering, and retrieval tasks, compared to simpler models like Bag of Words.\n",
    "\n",
    "### Steps covered in this notebook:\n",
    "1. Text Preprocessing (Tokenization, Lowercasing, Stopword Removal)\n",
    "2. TF-IDF Vectorization\n",
    "3. N-Gram Creation (Bigrams, Trigrams)\n",
    "4. Combining N-Grams with TF-IDF\n",
    "5. Visualization and Feature Exploration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting stanza\n",
      "  Downloading stanza-1.9.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting emoji (from stanza)\n",
      "  Downloading emoji-2.13.2-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: numpy in c:\\aplica\\nlp\\.venv\\lib\\site-packages (from stanza) (2.1.1)\n",
      "Collecting protobuf>=3.15.0 (from stanza)\n",
      "  Downloading protobuf-5.28.2-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Collecting requests (from stanza)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting networkx (from stanza)\n",
      "  Downloading networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting torch>=1.3.0 (from stanza)\n",
      "  Downloading torch-2.4.1-cp310-cp310-win_amd64.whl.metadata (27 kB)\n",
      "Requirement already satisfied: tqdm in c:\\aplica\\nlp\\.venv\\lib\\site-packages (from stanza) (4.66.5)\n",
      "Collecting tomli (from stanza)\n",
      "  Downloading tomli-2.0.1-py3-none-any.whl.metadata (8.9 kB)\n",
      "Collecting filelock (from torch>=1.3.0->stanza)\n",
      "  Downloading filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\aplica\\nlp\\.venv\\lib\\site-packages (from torch>=1.3.0->stanza) (4.12.2)\n",
      "Collecting sympy (from torch>=1.3.0->stanza)\n",
      "  Downloading sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting jinja2 (from torch>=1.3.0->stanza)\n",
      "  Downloading jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting fsspec (from torch>=1.3.0->stanza)\n",
      "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->stanza)\n",
      "  Downloading charset_normalizer-3.3.2-cp310-cp310-win_amd64.whl.metadata (34 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->stanza)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->stanza)\n",
      "  Downloading urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->stanza)\n",
      "  Downloading certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: colorama in c:\\aplica\\nlp\\.venv\\lib\\site-packages (from tqdm->stanza) (0.4.6)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=1.3.0->stanza)\n",
      "  Downloading MarkupSafe-2.1.5-cp310-cp310-win_amd64.whl.metadata (3.1 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch>=1.3.0->stanza)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Downloading stanza-1.9.2-py3-none-any.whl (1.1 MB)\n",
      "   ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.1/1.1 MB 25.8 MB/s eta 0:00:00\n",
      "Downloading protobuf-5.28.2-cp310-abi3-win_amd64.whl (431 kB)\n",
      "Downloading torch-2.4.1-cp310-cp310-win_amd64.whl (199.4 MB)\n",
      "   ---------------------------------------- 0.0/199.4 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 11.8/199.4 MB 56.8 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 20.2/199.4 MB 49.0 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 28.3/199.4 MB 44.9 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 36.2/199.4 MB 42.6 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 43.8/199.4 MB 41.6 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 51.1/199.4 MB 40.7 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 59.8/199.4 MB 40.5 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 68.9/199.4 MB 40.7 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 76.8/199.4 MB 40.1 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 81.3/199.4 MB 38.7 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 89.9/199.4 MB 38.5 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 97.5/199.4 MB 38.7 MB/s eta 0:00:03\n",
      "   -------------------- ------------------ 105.9/199.4 MB 38.6 MB/s eta 0:00:03\n",
      "   ---------------------- ---------------- 114.6/199.4 MB 38.9 MB/s eta 0:00:03\n",
      "   ------------------------ -------------- 123.2/199.4 MB 38.9 MB/s eta 0:00:02\n",
      "   ------------------------- ------------- 132.4/199.4 MB 39.3 MB/s eta 0:00:02\n",
      "   --------------------------- ----------- 141.6/199.4 MB 39.7 MB/s eta 0:00:02\n",
      "   ----------------------------- --------- 150.5/199.4 MB 39.9 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 160.2/199.4 MB 40.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ----- 170.1/199.4 MB 40.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 179.3/199.4 MB 40.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 188.5/199.4 MB 40.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  198.7/199.4 MB 41.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.2/199.4 MB 41.1 MB/s eta 0:00:01\n",
      "   --------------------------------------- 199.4/199.4 MB 38.5 MB/s eta 0:00:00\n",
      "Downloading emoji-2.13.2-py3-none-any.whl (553 kB)\n",
      "   ---------------------------------------- 0.0/553.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 553.2/553.2 kB 19.4 MB/s eta 0:00:00\n",
      "Downloading networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.7/1.7 MB 96.0 MB/s eta 0:00:00\n",
      "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading tomli-2.0.1-py3-none-any.whl (12 kB)\n",
      "Downloading certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "Downloading charset_normalizer-3.3.2-cp310-cp310-win_amd64.whl (100 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Downloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "Downloading jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "Downloading sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 6.2/6.2 MB 47.4 MB/s eta 0:00:00\n",
      "Downloading MarkupSafe-2.1.5-cp310-cp310-win_amd64.whl (17 kB)\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 536.2/536.2 kB 17.1 MB/s eta 0:00:00\n",
      "Installing collected packages: mpmath, urllib3, tomli, sympy, protobuf, networkx, MarkupSafe, idna, fsspec, filelock, emoji, charset-normalizer, certifi, requests, jinja2, torch, stanza\n",
      "Successfully installed MarkupSafe-2.1.5 certifi-2024.8.30 charset-normalizer-3.3.2 emoji-2.13.2 filelock-3.16.1 fsspec-2024.9.0 idna-3.10 jinja2-3.1.4 mpmath-1.3.0 networkx-3.3 protobuf-5.28.2 requests-2.32.3 stanza-1.9.2 sympy-1.13.3 tomli-2.0.1 torch-2.4.1 urllib3-2.2.3\n"
     ]
    }
   ],
   "source": [
    "!pip install stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "import stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"\"\"\n",
    "MARTIN LUTHER KING.\n",
    "Marcha sobre Washington por el Trabajo y la Libertad. 28 de agosto de 1963\n",
    "\n",
    "“Tengo un sueño”\n",
    "\n",
    "Estoy contento de reunirme hoy con vosotros y con vosotras en la que pasará a la historia como la mayor manifestación por la libertad en la historia de nuestra nación.\n",
    "Hace un siglo, un gran americano, bajo cuya simbólica sombra nos encontramos, firmó la Proclamación de Emancipación. Este trascendental decreto llegó como un gran faro de esperanza para millones de esclavos negros y esclavas negras, que habían sido quemados en las llamas de una injusticia aniquiladora. Llegó como un amanecer dichoso para acabar con la larga noche de su cautividad.\n",
    "Pero cien años después, las personas negras todavía no son libres. Cien años después, la vida de las personas negras sigue todavía tristemente atenazada por los grilletes de la segregación y por las cadenas de la discriminación. Cien años después, las personas negras viven en una isla solitaria de pobreza en medio de un vasto océano de prosperidad material. Cien años después, las personas negras todavía siguen languideciendo en los rincones de la sociedad americana y se sienten como exiliadas en su propia tierra. Así que hemos venido hoy aquí a mostrar unas condiciones vergonzosas.\n",
    "Hemos venido a la capital de nuestra nación en cierto sentido para cobrar un cheque. Cuando los arquitectos de nuestra república escribieron las magnificientes palabras de la Constitución y de la Declaración de Independencia, estaban firmando un pagaré del que todo americano iba a ser heredero. Este pagaré era una promesa de que a todos los hombres — sí, a los hombres negros y también a los hombres blancos— se les garantizarían los derechos inalienables a la vida, a la libertad y a la búsqueda de la felicidad.\n",
    "Hoy es obvio que América ha defraudado en este pagaré en lo que se refiere a sus ciudadanos y ciudadanas de color. En vez de cumplir con esta sagrada obligación, América ha dado al pueblo negro un cheque malo, un cheque que ha sido devuelto marcado “sin fondos”.\n",
    " \n",
    "Pero nos negamos a creer que el banco de la justicia está en bancarrota. Nos negamos a creer que no hay fondos suficientes en las grandes arcas bancarias de las oportunidades de esta nación. Así que hemos venido a cobrar este cheque, un cheque que nos dé mediante reclamación las riquezas de la libertad y la seguridad de la justicia. También hemos venido a este santo lugar para recordar a América la intensa urgencia de este momento. No es tiempo de darse al lujo de refrescarse o de tomar el tranquilizante del gradualismo. Ahora es tiempo de hacer que las promesas de democracia sean reales. Ahora es tiempo de subir desde el oscuro y desolado valle de la segregación al soleado sendero de la justicia racial. Ahora es tiempo de alzar a nuestra nación desde las arenas movedizas de la injusticia racial a la sólida roca de la fraternidad. Ahora es tiempo de hacer que la justicia sea una realidad para todos los hijos de Dios.\n",
    "Sería desastroso para la nación pasar por alto la urgencia del momento y subestimar la determinación de las personas negras. Este asfixiante verano del legítimo descontento de las personas negras no pasará hasta que haya un estimulante otoño de libertad e igualdad. Mil novecientos sesenta y tres no es un fin, sino un comienzo. Quienes esperaban que las personas negras necesitaran soltar vapor y que ahora estarán contentos, tendrán un brusco despertar si la nación vuelve a su actividad como si nada hubiera pasado. No habrá descanso ni tranquilidad en América hasta que las personas negras tengan garantizados sus derechos como ciudadanas y ciudadanos. Los torbellinos de revuelta continuarán sacudiendo los cimientos de nuestra nación hasta que nazca el día brillante de la justicia.\n",
    "Pero hay algo que debo decir a mi pueblo, que está en el caluroso umbral que lleva al interior del palacio de justicia. En el proceso de conseguir nuestro legítimo lugar, no debemos ser culpables de acciones equivocadas. No busquemos saciar nuestra sed de libertad bebiendo de la copa del encarnizamiento y del odio. Debemos conducir siempre nuestra lucha en el elevado nivel de la dignidad y la disciplina. No debemos permitir que nuestra fecunda protesta degenere en violencia física. Una y otra vez debemos ascender a las majestuosas alturas donde se hace frente a la fuerza física con la fuerza espiritual. La maravillosa nueva militancia que ha envuelto a la comunidad negra no debe llevarnos a desconfiar de todas las personas blancas, ya que muchos de nuestros hermanos blancos, como su presencia hoy aquí evidencia, han llegado a ser conscientes de que su destino está atado a nuestro destino.\n",
    " \n",
    "Han llegado a darse cuenta de que su libertad está inextricablemente unida a nuestra libertad. No podemos caminar solos.\n",
    "Y mientras caminamos, debemos hacer la solemne promesa de que siempre caminaremos hacia adelante. No podemos volver atrás. Hay quienes están preguntando a los defensores de los derechos civiles: “¿Cuándo estaréis satisfechos?” No podemos estar satisfechos mientras las personas negras sean víctimas de los indecibles horrores de la brutalidad de la policía. No podemos estar satisfechos mientras nuestros cuerpos, cargados con la fatiga del viaje, no puedan conseguir alojamiento en los moteles de las autopistas ni en los hoteles de las ciudades. No podemos estar satisfechos mientras la movilidad básica de las personas negras sea de un ghetto más pequeño a otro más amplio. No podemos estar satisfechos mientras nuestros hijos sean despojados de su personalidad y privados de su dignidad por letreros que digan “sólo para blancos”. No podemos estar satisfechos mientras una persona negra en Mississippi no pueda votar y una persona negra en Nueva York crea que no tiene nada por qué votar. No, no, no estamos satisfechos y no estaremos satisfechos hasta que la justicia corra como las aguas y la rectitud como un impetuoso torrente.\n",
    "No soy inconsciente de que algunos de vosotros y vosotras habéis venido aquí después de grandes procesos y tribulaciones. Algunos de vosotros y vosotras habéis salido recientemente de estrechas celdas de una prisión. Algunos de vosotros y vosotras habéis venido de zonas donde vuestra búsqueda de la libertad os dejó golpeados por las tormentas de la persecución y tambaleantes por los vientos de la brutalidad de la policía. Habéis sido los veteranos del sufrimiento fecundo. Continuad trabajando con la fe de que el sufrimiento inmerecido es redención.\n",
    "Volved a Mississippi, volved a Alabama, volved a Carolina del Sur, volved a Georgia, volved a Luisiana, volved a los suburbios y a los ghettos de nuestras ciudades del Norte, sabiendo que de un modo u otro esta situación puede y va a ser cambiada.\n",
    "No nos hundamos en el valle de la desesperación. Aun así, aunque\n",
    "vemos delante las dificultades de hoy y mañana, amigos míos, os digo hoy: todavía tengo un sueño. Es un sueño profundamente enraizado en el sueño americano.\n",
    "Tengo un sueño: que un día esta nación se pondrá en pie y realizará el verdadero significado de su credo: “Sostenemos que estas verdades son evidentes por sí mismas: que todos los hombres han sido creados iguales”.\n",
    " \n",
    "Tengo un sueño: que un día sobre las colinas rojas de Georgia los hijos de quienes fueron esclavos y los hijos de quienes fueron propietarios de esclavos serán capaces de sentarse juntos en la mesa de la fraternidad.\n",
    "Tengo un sueño: que un día incluso el estado de Mississippi, un estado sofocante por el calor de la injusticia, sofocante por el calor de la opresión, se transformará en un oasis de libertad y justicia.\n",
    "Tengo un sueño: que mis cuatro hijos vivirán un día en una nación en la que no serán juzgados por el color de su piel sino por su reputación.\n",
    "Tengo un sueño hoy.\n",
    "Tengo un sueño: que un día allá abajo en Alabama, con sus racistas despiadados, con su gobernador que tiene los labios goteando con las palabras de interposición y anulación, que un día, justo allí en Alabama niños negros y niñas negras podrán darse la mano con niños blancos y niñas blancas, como hermanas y hermanos.\n",
    "Tengo un sueño hoy.\n",
    "Tengo un sueño: que un día todo valle será alzado y toda colina y montaña será bajada, los lugares escarpados se harán llanos y los lugares tortuosos se enderezarán y la gloria del Señor se mostrará y toda la carne juntamente la verá.\n",
    "Ésta es nuestra esperanza. Ésta es la fe con la que yo vuelvo al Sur. Con esta fe seremos capaces de cortar de la montaña de desesperación una piedra de esperanza. Con esta fe seremos capaces de transformar las chirriantes disonancias de nuestra nación en una hermosa sinfonía de fraternidad. Con esta fe seremos capaces de trabajar juntos, de rezar juntos, de luchar juntos, de ir a la cárcel juntos, de ponernos de pie juntos por la libertad, sabiendo que un día seremos libres.\n",
    "Éste será el día, éste será el día en el que todos los hijos de Dios podrán cantar con un nuevo significado “Tierra mía, es a ti, dulce tierra de libertad, a ti te canto. Tierra donde mi padre ha muerto, tierra del orgullo del peregrino, desde cada ladera suene la libertad”.\n",
    "Y si América va a ser una gran nación, esto tiene que llegar a ser verdad. Y así, suene la libertad desde las prodigiosas cumbres de las colinas de New Hampshire. Suene la libertad desde las enormes montañas de Nueva York. Suene la libertad desde los elevados Alleghenies de Pennsylvania.\n",
    "Suene la libertad desde las Rocosas cubiertas de nieve de Colorado. Suene la libertad desde las curvas vertientes de California.\n",
    " \n",
    "Pero no sólo eso; suene la libertad desde la Montaña de Piedra de Georgia.\n",
    "Suene la libertad desde el Monte Lookout de Tennessee.\n",
    "Suene la libertad desde cada colina y cada topera de Mississippi, desde cada ladera.\n",
    "Suene la libertad. Y cuando esto ocurra y cuando permitamos que la libertad suene, cuando la dejemos sonar desde cada pueblo y cada aldea, desde cada estado y cada ciudad, podremos acelerar la llegada de aquel día en el que todos los hijos de Dios, hombres blancos y hombres negros, judíos y gentiles, protestantes y católicos, serán capaces de juntar las manos y cantar con las palabras del viejo espiritual negro: “¡Al fin libres!\n",
    "¡Al fin libres! ¡Gracias a Dios Todopoderoso, somos al fin libres!”\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\bleew\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\bleew\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Text Preprocessing\n",
    "\n",
    "Before applying the TF-IDF and N-Gram models, we need to preprocess the text data to ensure consistency and remove irrelevant information. Preprocessing includes the following steps:\n",
    "\n",
    "1. **Tokenization**: Splitting the text into individual words (tokens).\n",
    "2. **Lowercasing**: Converting all characters to lowercase to avoid case-sensitive variations of the same word.\n",
    "3. **Removing Stop Words**: Eliminating common words like \"the\", \"is\", and \"and\" which do not add significant value to the text analysis.\n",
    "4. **Removing Special Characters**: Cleaning the text by removing punctuation and non-alphabetic characters to focus on meaningful words.\n",
    "\n",
    "This step is crucial for improving the quality of the final text representation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = nltk.sent_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nMARTIN LUTHER KING.',\n",
       " 'Marcha sobre Washington por el Trabajo y la Libertad.',\n",
       " '28 de agosto de 1963\\n\\n“Tengo un sueño”\\n\\nEstoy contento de reunirme hoy con vosotros y con vosotras en la que pasará a la historia como la mayor manifestación por la libertad en la historia de nuestra nación.',\n",
       " 'Hace un siglo, un gran americano, bajo cuya simbólica sombra nos encontramos, firmó la Proclamación de Emancipación.',\n",
       " 'Este trascendental decreto llegó como un gran faro de esperanza para millones de esclavos negros y esclavas negras, que habían sido quemados en las llamas de una injusticia aniquiladora.',\n",
       " 'Llegó como un amanecer dichoso para acabar con la larga noche de su cautividad.',\n",
       " 'Pero cien años después, las personas negras todavía no son libres.',\n",
       " 'Cien años después, la vida de las personas negras sigue todavía tristemente atenazada por los grilletes de la segregación y por las cadenas de la discriminación.',\n",
       " 'Cien años después, las personas negras viven en una isla solitaria de pobreza en medio de un vasto océano de prosperidad material.',\n",
       " 'Cien años después, las personas negras todavía siguen languideciendo en los rincones de la sociedad americana y se sienten como exiliadas en su propia tierra.',\n",
       " 'Así que hemos venido hoy aquí a mostrar unas condiciones vergonzosas.',\n",
       " 'Hemos venido a la capital de nuestra nación en cierto sentido para cobrar un cheque.',\n",
       " 'Cuando los arquitectos de nuestra república escribieron las magnificientes palabras de la Constitución y de la Declaración de Independencia, estaban firmando un pagaré del que todo americano iba a ser heredero.',\n",
       " 'Este pagaré era una promesa de que a todos los hombres — sí, a los hombres negros y también a los hombres blancos— se les garantizarían los derechos inalienables a la vida, a la libertad y a la búsqueda de la felicidad.',\n",
       " 'Hoy es obvio que América ha defraudado en este pagaré en lo que se refiere a sus ciudadanos y ciudadanas de color.',\n",
       " 'En vez de cumplir con esta sagrada obligación, América ha dado al pueblo negro un cheque malo, un cheque que ha sido devuelto marcado “sin fondos”.',\n",
       " 'Pero nos negamos a creer que el banco de la justicia está en bancarrota.',\n",
       " 'Nos negamos a creer que no hay fondos suficientes en las grandes arcas bancarias de las oportunidades de esta nación.',\n",
       " 'Así que hemos venido a cobrar este cheque, un cheque que nos dé mediante reclamación las riquezas de la libertad y la seguridad de la justicia.',\n",
       " 'También hemos venido a este santo lugar para recordar a América la intensa urgencia de este momento.',\n",
       " 'No es tiempo de darse al lujo de refrescarse o de tomar el tranquilizante del gradualismo.',\n",
       " 'Ahora es tiempo de hacer que las promesas de democracia sean reales.',\n",
       " 'Ahora es tiempo de subir desde el oscuro y desolado valle de la segregación al soleado sendero de la justicia racial.',\n",
       " 'Ahora es tiempo de alzar a nuestra nación desde las arenas movedizas de la injusticia racial a la sólida roca de la fraternidad.',\n",
       " 'Ahora es tiempo de hacer que la justicia sea una realidad para todos los hijos de Dios.',\n",
       " 'Sería desastroso para la nación pasar por alto la urgencia del momento y subestimar la determinación de las personas negras.',\n",
       " 'Este asfixiante verano del legítimo descontento de las personas negras no pasará hasta que haya un estimulante otoño de libertad e igualdad.',\n",
       " 'Mil novecientos sesenta y tres no es un fin, sino un comienzo.',\n",
       " 'Quienes esperaban que las personas negras necesitaran soltar vapor y que ahora estarán contentos, tendrán un brusco despertar si la nación vuelve a su actividad como si nada hubiera pasado.',\n",
       " 'No habrá descanso ni tranquilidad en América hasta que las personas negras tengan garantizados sus derechos como ciudadanas y ciudadanos.',\n",
       " 'Los torbellinos de revuelta continuarán sacudiendo los cimientos de nuestra nación hasta que nazca el día brillante de la justicia.',\n",
       " 'Pero hay algo que debo decir a mi pueblo, que está en el caluroso umbral que lleva al interior del palacio de justicia.',\n",
       " 'En el proceso de conseguir nuestro legítimo lugar, no debemos ser culpables de acciones equivocadas.',\n",
       " 'No busquemos saciar nuestra sed de libertad bebiendo de la copa del encarnizamiento y del odio.',\n",
       " 'Debemos conducir siempre nuestra lucha en el elevado nivel de la dignidad y la disciplina.',\n",
       " 'No debemos permitir que nuestra fecunda protesta degenere en violencia física.',\n",
       " 'Una y otra vez debemos ascender a las majestuosas alturas donde se hace frente a la fuerza física con la fuerza espiritual.',\n",
       " 'La maravillosa nueva militancia que ha envuelto a la comunidad negra no debe llevarnos a desconfiar de todas las personas blancas, ya que muchos de nuestros hermanos blancos, como su presencia hoy aquí evidencia, han llegado a ser conscientes de que su destino está atado a nuestro destino.',\n",
       " 'Han llegado a darse cuenta de que su libertad está inextricablemente unida a nuestra libertad.',\n",
       " 'No podemos caminar solos.',\n",
       " 'Y mientras caminamos, debemos hacer la solemne promesa de que siempre caminaremos hacia adelante.',\n",
       " 'No podemos volver atrás.',\n",
       " 'Hay quienes están preguntando a los defensores de los derechos civiles: “¿Cuándo estaréis satisfechos?” No podemos estar satisfechos mientras las personas negras sean víctimas de los indecibles horrores de la brutalidad de la policía.',\n",
       " 'No podemos estar satisfechos mientras nuestros cuerpos, cargados con la fatiga del viaje, no puedan conseguir alojamiento en los moteles de las autopistas ni en los hoteles de las ciudades.',\n",
       " 'No podemos estar satisfechos mientras la movilidad básica de las personas negras sea de un ghetto más pequeño a otro más amplio.',\n",
       " 'No podemos estar satisfechos mientras nuestros hijos sean despojados de su personalidad y privados de su dignidad por letreros que digan “sólo para blancos”.',\n",
       " 'No podemos estar satisfechos mientras una persona negra en Mississippi no pueda votar y una persona negra en Nueva York crea que no tiene nada por qué votar.',\n",
       " 'No, no, no estamos satisfechos y no estaremos satisfechos hasta que la justicia corra como las aguas y la rectitud como un impetuoso torrente.',\n",
       " 'No soy inconsciente de que algunos de vosotros y vosotras habéis venido aquí después de grandes procesos y tribulaciones.',\n",
       " 'Algunos de vosotros y vosotras habéis salido recientemente de estrechas celdas de una prisión.',\n",
       " 'Algunos de vosotros y vosotras habéis venido de zonas donde vuestra búsqueda de la libertad os dejó golpeados por las tormentas de la persecución y tambaleantes por los vientos de la brutalidad de la policía.',\n",
       " 'Habéis sido los veteranos del sufrimiento fecundo.',\n",
       " 'Continuad trabajando con la fe de que el sufrimiento inmerecido es redención.',\n",
       " 'Volved a Mississippi, volved a Alabama, volved a Carolina del Sur, volved a Georgia, volved a Luisiana, volved a los suburbios y a los ghettos de nuestras ciudades del Norte, sabiendo que de un modo u otro esta situación puede y va a ser cambiada.',\n",
       " 'No nos hundamos en el valle de la desesperación.',\n",
       " 'Aun así, aunque\\nvemos delante las dificultades de hoy y mañana, amigos míos, os digo hoy: todavía tengo un sueño.',\n",
       " 'Es un sueño profundamente enraizado en el sueño americano.',\n",
       " 'Tengo un sueño: que un día esta nación se pondrá en pie y realizará el verdadero significado de su credo: “Sostenemos que estas verdades son evidentes por sí mismas: que todos los hombres han sido creados iguales”.',\n",
       " 'Tengo un sueño: que un día sobre las colinas rojas de Georgia los hijos de quienes fueron esclavos y los hijos de quienes fueron propietarios de esclavos serán capaces de sentarse juntos en la mesa de la fraternidad.',\n",
       " 'Tengo un sueño: que un día incluso el estado de Mississippi, un estado sofocante por el calor de la injusticia, sofocante por el calor de la opresión, se transformará en un oasis de libertad y justicia.',\n",
       " 'Tengo un sueño: que mis cuatro hijos vivirán un día en una nación en la que no serán juzgados por el color de su piel sino por su reputación.',\n",
       " 'Tengo un sueño hoy.',\n",
       " 'Tengo un sueño: que un día allá abajo en Alabama, con sus racistas despiadados, con su gobernador que tiene los labios goteando con las palabras de interposición y anulación, que un día, justo allí en Alabama niños negros y niñas negras podrán darse la mano con niños blancos y niñas blancas, como hermanas y hermanos.',\n",
       " 'Tengo un sueño hoy.',\n",
       " 'Tengo un sueño: que un día todo valle será alzado y toda colina y montaña será bajada, los lugares escarpados se harán llanos y los lugares tortuosos se enderezarán y la gloria del Señor se mostrará y toda la carne juntamente la verá.',\n",
       " 'Ésta es nuestra esperanza.',\n",
       " 'Ésta es la fe con la que yo vuelvo al Sur.',\n",
       " 'Con esta fe seremos capaces de cortar de la montaña de desesperación una piedra de esperanza.',\n",
       " 'Con esta fe seremos capaces de transformar las chirriantes disonancias de nuestra nación en una hermosa sinfonía de fraternidad.',\n",
       " 'Con esta fe seremos capaces de trabajar juntos, de rezar juntos, de luchar juntos, de ir a la cárcel juntos, de ponernos de pie juntos por la libertad, sabiendo que un día seremos libres.',\n",
       " 'Éste será el día, éste será el día en el que todos los hijos de Dios podrán cantar con un nuevo significado “Tierra mía, es a ti, dulce tierra de libertad, a ti te canto.',\n",
       " 'Tierra donde mi padre ha muerto, tierra del orgullo del peregrino, desde cada ladera suene la libertad”.',\n",
       " 'Y si América va a ser una gran nación, esto tiene que llegar a ser verdad.',\n",
       " 'Y así, suene la libertad desde las prodigiosas cumbres de las colinas de New Hampshire.',\n",
       " 'Suene la libertad desde las enormes montañas de Nueva York.',\n",
       " 'Suene la libertad desde los elevados Alleghenies de Pennsylvania.',\n",
       " 'Suene la libertad desde las Rocosas cubiertas de nieve de Colorado.',\n",
       " 'Suene la libertad desde las curvas vertientes de California.',\n",
       " 'Pero no sólo eso; suene la libertad desde la Montaña de Piedra de Georgia.',\n",
       " 'Suene la libertad desde el Monte Lookout de Tennessee.',\n",
       " 'Suene la libertad desde cada colina y cada topera de Mississippi, desde cada ladera.',\n",
       " 'Suene la libertad.',\n",
       " 'Y cuando esto ocurra y cuando permitamos que la libertad suene, cuando la dejemos sonar desde cada pueblo y cada aldea, desde cada estado y cada ciudad, podremos acelerar la llegada de aquel día en el que todos los hijos de Dios, hombres blancos y hombres negros, judíos y gentiles, protestantes y católicos, serán capaces de juntar las manos y cantar con las palabras del viejo espiritual negro: “¡Al fin libres!',\n",
       " '¡Al fin libres!',\n",
       " '¡Gracias a Dios Todopoderoso, somos al fin libres!”']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_spanish_sw = set(stopwords.words('spanish'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_punctuation = string.punctuation + '¿¡“”'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.9.0.json: 392kB [00:00, 60.5MB/s]                    \n",
      "2024-10-01 11:35:48 INFO: Downloaded file to C:\\Users\\bleew\\stanza_resources\\resources.json\n",
      "2024-10-01 11:35:48 INFO: Downloading default packages for language: es (Spanish) ...\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-es/resolve/v1.9.0/models/default.zip: 100%|██████████| 642M/642M [00:14<00:00, 43.9MB/s] \n",
      "2024-10-01 11:36:04 INFO: Downloaded file to C:\\Users\\bleew\\stanza_resources\\es\\default.zip\n",
      "2024-10-01 11:36:07 INFO: Finished downloading models and saved to C:\\Users\\bleew\\stanza_resources\n"
     ]
    }
   ],
   "source": [
    "stanza.download('es')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-01 11:36:35 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.9.0.json: 392kB [00:00, 46.6MB/s]                    \n",
      "2024-10-01 11:36:35 INFO: Downloaded file to C:\\Users\\bleew\\stanza_resources\\resources.json\n",
      "2024-10-01 11:36:36 INFO: Loading these models for language: es (Spanish):\n",
      "====================================\n",
      "| Processor    | Package           |\n",
      "------------------------------------\n",
      "| tokenize     | combined          |\n",
      "| mwt          | combined          |\n",
      "| pos          | combined_charlm   |\n",
      "| lemma        | combined_nocharlm |\n",
      "| constituency | combined_charlm   |\n",
      "| depparse     | combined_charlm   |\n",
      "| sentiment    | tass2020_charlm   |\n",
      "| ner          | conll02           |\n",
      "====================================\n",
      "\n",
      "2024-10-01 11:36:36 INFO: Using device: cpu\n",
      "2024-10-01 11:36:36 INFO: Loading: tokenize\n",
      "c:\\aplica\\NLP\\.venv\\lib\\site-packages\\stanza\\models\\tokenization\\trainer.py:82: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "2024-10-01 11:36:37 INFO: Loading: mwt\n",
      "c:\\aplica\\NLP\\.venv\\lib\\site-packages\\stanza\\models\\mwt\\trainer.py:201: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "2024-10-01 11:36:37 INFO: Loading: pos\n",
      "c:\\aplica\\NLP\\.venv\\lib\\site-packages\\stanza\\models\\pos\\trainer.py:139: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "c:\\aplica\\NLP\\.venv\\lib\\site-packages\\stanza\\models\\common\\pretrain.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(self.filename, lambda storage, loc: storage)\n",
      "c:\\aplica\\NLP\\.venv\\lib\\site-packages\\stanza\\models\\common\\char_model.py:271: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(filename, lambda storage, loc: storage)\n",
      "2024-10-01 11:36:37 INFO: Loading: lemma\n",
      "c:\\aplica\\NLP\\.venv\\lib\\site-packages\\stanza\\models\\lemma\\trainer.py:239: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "2024-10-01 11:36:37 INFO: Loading: constituency\n",
      "c:\\aplica\\NLP\\.venv\\lib\\site-packages\\stanza\\models\\constituency\\base_trainer.py:87: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "2024-10-01 11:36:38 INFO: Loading: depparse\n",
      "c:\\aplica\\NLP\\.venv\\lib\\site-packages\\stanza\\models\\depparse\\trainer.py:194: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "2024-10-01 11:36:38 INFO: Loading: sentiment\n",
      "c:\\aplica\\NLP\\.venv\\lib\\site-packages\\stanza\\models\\classifiers\\trainer.py:72: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "2024-10-01 11:36:38 INFO: Loading: ner\n",
      "c:\\aplica\\NLP\\.venv\\lib\\site-packages\\stanza\\models\\ner\\trainer.py:197: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "2024-10-01 11:36:39 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "nlp = stanza.Pipeline('es')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Pipeline in module stanza.pipeline.core object:\n",
      "\n",
      "class Pipeline(builtins.object)\n",
      " |  Pipeline(lang='en', dir='C:\\\\Users\\\\bleew\\\\stanza_resources', package='default', processors={}, logging_level=None, verbose=None, use_gpu=None, model_dir=None, download_method=<DownloadMethod.DOWNLOAD_RESOURCES: 3>, resources_url='https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main', resources_branch=None, resources_version='1.9.0', resources_filepath=None, proxies=None, foundation_cache=None, device=None, allow_unknown_language=False, **kwargs)\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __call__(self, doc, processors=None)\n",
      " |      Call self as a function.\n",
      " |  \n",
      " |  __init__(self, lang='en', dir='C:\\\\Users\\\\bleew\\\\stanza_resources', package='default', processors={}, logging_level=None, verbose=None, use_gpu=None, model_dir=None, download_method=<DownloadMethod.DOWNLOAD_RESOURCES: 3>, resources_url='https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main', resources_branch=None, resources_version='1.9.0', resources_filepath=None, proxies=None, foundation_cache=None, device=None, allow_unknown_language=False, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Assemble the processors in order to make a simple description of the pipeline\n",
      " |  \n",
      " |  bulk_process(self, docs, *args, **kwargs)\n",
      " |      Run the pipeline in bulk processing mode\n",
      " |      \n",
      " |      Expects a list of str or a list of Docs\n",
      " |  \n",
      " |  process(self, doc, processors=None)\n",
      " |      Run the pipeline\n",
      " |      \n",
      " |      processors: allow for a list of processors used by this pipeline action\n",
      " |        can be list, tuple, set, or comma separated string\n",
      " |        if None, use all the processors this pipeline knows about\n",
      " |        MWT is added if necessary\n",
      " |        otherwise, no care is taken to make sure prerequisites are followed...\n",
      " |          some of the annotators, such as depparse, will check, but others\n",
      " |          will fail in some unusual manner or just have really bad results\n",
      " |  \n",
      " |  stream(self, docs, batch_size=50, *args, **kwargs)\n",
      " |      Go through an iterator of documents in batches, yield processed documents\n",
      " |      \n",
      " |      sentence indices will be counted across the entire iterator\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  filter_config(prefix, config_dict)\n",
      " |  \n",
      " |  update_kwargs(kwargs, processor_list)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  loaded_processors\n",
      " |      Return all currently loaded processors in execution order.\n",
      " |      :return: list of Processor instances\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sentences)):\n",
    "    sentences[i] = sentences[i].lower().translate(str.maketrans('', '', custom_punctuation))\n",
    "    doc = nlp(sentences[i])\n",
    "    words = [word.lemma for words in doc.sentences for word in words.words if word not in unique_spanish_sw]\n",
    "    sentences[i] = ' '.join(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing how to handle Stanza lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"id\": 1,\n",
      "    \"text\": \"Estoy\",\n",
      "    \"lemma\": \"estar\",\n",
      "    \"upos\": \"AUX\",\n",
      "    \"xpos\": \"vmip1s0\",\n",
      "    \"feats\": \"Mood=Ind|Number=Sing|Person=1|Tense=Pres|VerbForm=Fin\",\n",
      "    \"head\": 2,\n",
      "    \"deprel\": \"aux\",\n",
      "    \"start_char\": 0,\n",
      "    \"end_char\": 5,\n",
      "    \"ner\": \"O\",\n",
      "    \"multi_ner\": [\n",
      "      \"O\"\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"id\": 2,\n",
      "    \"text\": \"corriendo\",\n",
      "    \"lemma\": \"correr\",\n",
      "    \"upos\": \"VERB\",\n",
      "    \"xpos\": \"vmg0000\",\n",
      "    \"feats\": \"VerbForm=Ger\",\n",
      "    \"head\": 0,\n",
      "    \"deprel\": \"root\",\n",
      "    \"start_char\": 6,\n",
      "    \"end_char\": 15,\n",
      "    \"ner\": \"O\",\n",
      "    \"multi_ner\": [\n",
      "      \"O\"\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"id\": 3,\n",
      "    \"text\": \"rápidamente\",\n",
      "    \"lemma\": \"rápidamente\",\n",
      "    \"upos\": \"ADV\",\n",
      "    \"xpos\": \"rg\",\n",
      "    \"head\": 2,\n",
      "    \"deprel\": \"advmod\",\n",
      "    \"start_char\": 16,\n",
      "    \"end_char\": 27,\n",
      "    \"ner\": \"O\",\n",
      "    \"multi_ner\": [\n",
      "      \"O\"\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"id\": 4,\n",
      "    \"text\": \"por\",\n",
      "    \"lemma\": \"por\",\n",
      "    \"upos\": \"ADP\",\n",
      "    \"xpos\": \"sps00\",\n",
      "    \"head\": 6,\n",
      "    \"deprel\": \"case\",\n",
      "    \"start_char\": 28,\n",
      "    \"end_char\": 31,\n",
      "    \"ner\": \"O\",\n",
      "    \"multi_ner\": [\n",
      "      \"O\"\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"id\": 5,\n",
      "    \"text\": \"el\",\n",
      "    \"lemma\": \"el\",\n",
      "    \"upos\": \"DET\",\n",
      "    \"xpos\": \"da0ms0\",\n",
      "    \"feats\": \"Definite=Def|Gender=Masc|Number=Sing|PronType=Art\",\n",
      "    \"head\": 6,\n",
      "    \"deprel\": \"det\",\n",
      "    \"start_char\": 32,\n",
      "    \"end_char\": 34,\n",
      "    \"ner\": \"O\",\n",
      "    \"multi_ner\": [\n",
      "      \"O\"\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"id\": 6,\n",
      "    \"text\": \"parque\",\n",
      "    \"lemma\": \"parque\",\n",
      "    \"upos\": \"NOUN\",\n",
      "    \"xpos\": \"ncms000\",\n",
      "    \"feats\": \"Gender=Masc|Number=Sing\",\n",
      "    \"head\": 2,\n",
      "    \"deprel\": \"obl\",\n",
      "    \"start_char\": 35,\n",
      "    \"end_char\": 41,\n",
      "    \"ner\": \"O\",\n",
      "    \"multi_ner\": [\n",
      "      \"O\"\n",
      "    ],\n",
      "    \"misc\": \"SpaceAfter=No\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Estoy corriendo rápidamente por el parque\")\n",
    "lemmatized_text = \" \".join([word.lemma for sent in doc.sentences for word in sent.words])\n",
    "print(doc.sentences[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estar\n",
      "correr\n",
      "rápidamente\n",
      "por\n",
      "el\n",
      "parque\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Estoy corriendo rápidamente por el parque\")\n",
    "# doc.sentences[0]\n",
    "for words in doc.sentences:\n",
    "    for word in words.words:\n",
    "        print(word.lemma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{\n",
       "   \"id\": 1,\n",
       "   \"text\": \"Estoy\",\n",
       "   \"lemma\": \"estar\",\n",
       "   \"upos\": \"AUX\",\n",
       "   \"xpos\": \"vmip1s0\",\n",
       "   \"feats\": \"Mood=Ind|Number=Sing|Person=1|Tense=Pres|VerbForm=Fin\",\n",
       "   \"head\": 2,\n",
       "   \"deprel\": \"aux\",\n",
       "   \"start_char\": 0,\n",
       "   \"end_char\": 5\n",
       " },\n",
       " {\n",
       "   \"id\": 2,\n",
       "   \"text\": \"corriendo\",\n",
       "   \"lemma\": \"correr\",\n",
       "   \"upos\": \"VERB\",\n",
       "   \"xpos\": \"vmg0000\",\n",
       "   \"feats\": \"VerbForm=Ger\",\n",
       "   \"head\": 0,\n",
       "   \"deprel\": \"root\",\n",
       "   \"start_char\": 6,\n",
       "   \"end_char\": 15\n",
       " },\n",
       " {\n",
       "   \"id\": 3,\n",
       "   \"text\": \"rápidamente\",\n",
       "   \"lemma\": \"rápidamente\",\n",
       "   \"upos\": \"ADV\",\n",
       "   \"xpos\": \"rg\",\n",
       "   \"head\": 2,\n",
       "   \"deprel\": \"advmod\",\n",
       "   \"start_char\": 16,\n",
       "   \"end_char\": 27\n",
       " },\n",
       " {\n",
       "   \"id\": 4,\n",
       "   \"text\": \"por\",\n",
       "   \"lemma\": \"por\",\n",
       "   \"upos\": \"ADP\",\n",
       "   \"xpos\": \"sps00\",\n",
       "   \"head\": 6,\n",
       "   \"deprel\": \"case\",\n",
       "   \"start_char\": 28,\n",
       "   \"end_char\": 31\n",
       " },\n",
       " {\n",
       "   \"id\": 5,\n",
       "   \"text\": \"el\",\n",
       "   \"lemma\": \"el\",\n",
       "   \"upos\": \"DET\",\n",
       "   \"xpos\": \"da0ms0\",\n",
       "   \"feats\": \"Definite=Def|Gender=Masc|Number=Sing|PronType=Art\",\n",
       "   \"head\": 6,\n",
       "   \"deprel\": \"det\",\n",
       "   \"start_char\": 32,\n",
       "   \"end_char\": 34\n",
       " },\n",
       " {\n",
       "   \"id\": 6,\n",
       "   \"text\": \"parque\",\n",
       "   \"lemma\": \"parque\",\n",
       "   \"upos\": \"NOUN\",\n",
       "   \"xpos\": \"ncms000\",\n",
       "   \"feats\": \"Gender=Masc|Number=Sing\",\n",
       "   \"head\": 2,\n",
       "   \"deprel\": \"obl\",\n",
       "   \"start_char\": 35,\n",
       "   \"end_char\": 41\n",
       " }]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.sentences[0].words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# See lemmatized phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['martin luther king',\n",
       " 'marcha washington trabajo libertad',\n",
       " '28 agosto 1963 sueño contento reunir yo hoy pasar historia mayor manifestación libertad historia nación',\n",
       " 'hacer siglo gran americano bajo cuyo simbólico sombra encontrar firmar proclamación emancipación',\n",
       " 'trascendental decreto llegar gran faro esperanza millón esclavo negro esclava negro ser quemar llamar injusticia aniquilador',\n",
       " 'llegar amanecer dichoso acabar largo noche cautividad',\n",
       " 'cien año después persona negro todavía libre',\n",
       " 'cien año después vida persona negro seguir todavía tristemente atenazado grillete segregación cadena discriminación',\n",
       " 'cien año después persona negro vivir isla solitario pobreza medio vasto océano prosperidad material',\n",
       " 'cien año después persona negro todavía seguir languidecer rincón sociedad americana sentir exiliado propio tierra',\n",
       " 'así venir hoy aquí mostrar uno condición vergonzoso',\n",
       " 'venir capital nación cierto cobrar cheque',\n",
       " 'arquitecto república escriber magnificiente palabra constitución declaración independencia firmar pagaré americano ir ser heredero',\n",
       " 'pagaré promesa hombre — hombre negro hombre blanco — garantizar derecho inalienable vida libertad búsqueda felicidad',\n",
       " 'hoy obvio américa defraudado pagaré referir ciudadano ciudadana color',\n",
       " 'vez cumplir sagrado obligación américo dado pueblo negro cheque malo cheque ser devolver marcado fondo',\n",
       " 'negar creer banco justicia bancarrota',\n",
       " 'negar creer fondo suficiente grande arca bancario oportunidad nación',\n",
       " 'así venir cobrar cheque cheque dar mediante reclamación riqueza libertad seguridad justicia',\n",
       " 'venir santo lugar recordar américa intenso urgencia momento',\n",
       " 'tiempo dar él lujo refrescar él tomar tranquilizante gradualismo',\n",
       " 'ahora tiempo hacer promesa democracia real',\n",
       " 'ahora tiempo subir oscuro desolado valle segregación soleado sendero justicia racial',\n",
       " 'ahora tiempo alzar nación arena movedizo injusticia racial sólido roca fraternidad',\n",
       " 'ahora tiempo hacer justicia realidad hijo dio',\n",
       " 'desastroso nación pasar alto urgencia momento subestimar determinación persona negro',\n",
       " 'asfixiante verano legítimo descontento persona negro pasar estimulante otoño libertad igualdad',\n",
       " 'mil novecientos sesenta tres fin sino comienzo',\n",
       " 'esperar persona negro necesitar soltar vapor ahora contento brusco despertar si nación volver actividad si pasado',\n",
       " 'descanso tranquilidad américo persona negro garantizado derecho ciudadana ciudadano',\n",
       " 'torbellino revuelta continuar sacuder cimiento nación nazcar día brillante justicia',\n",
       " 'deber decir pueblo caluroso umbral llevar interior palacio justicia',\n",
       " 'proceso conseguir legítimo lugar deber ser culpable acción equivocado',\n",
       " 'busquemo saciar sed libertad beber copa encarnizamiento odio',\n",
       " 'deber conducir siempre lucha elevado nivel dignidad disciplina',\n",
       " 'deber permitir fecundo protesta degener violencia físico',\n",
       " 'vez deber ascender majestuoso altura hacer frente fuerza físico fuerza espiritual',\n",
       " 'maravilloso nuevo militancia envuelto comunidad negro deber llevar yo desconfiar todo persona blanco hermano blanco presencia hoy aquí evidenciar llegado ser consciente destino atado destino',\n",
       " 'llegado dar él cuenta libertad inextricablemente unido libertad',\n",
       " 'poder caminar sólo',\n",
       " 'mientras caminar deber hacer solemne promesa siempre caminar hacia adelante',\n",
       " 'poder volver atrás',\n",
       " 'preguntar defensor derecho civil cuándo satisfecho poder satisfecho mientras persona negro víctima indecible horror brutalidad policía',\n",
       " 'poder satisfecho mientras cuerpo cargado fatiga viaje poder conseguir alojamiento motel autopista hotel ciudad',\n",
       " 'poder satisfecho mientras movilidad básico persona negro ghetto pequeño amplio',\n",
       " 'poder satisfecho mientras hijo despojado personalidad privado dignidad letrero decir sólo blanco',\n",
       " 'poder satisfecho mientras persona negro mississippi poder votar persona negro nuevo york creer votar',\n",
       " 'satisfecho satisfecho justicia corrar agua rectitud impetuoso torrente',\n",
       " 'inconsciente venir aquí después grande proceso tribulación',\n",
       " 'salir recientemente estrecho celda prisión',\n",
       " 'venir zona búsqueda libertad dejar golpeado tormenta persecución tambaleante viento brutalidad policía',\n",
       " 'ser veterano sufrimiento fecundo',\n",
       " 'continuad trabajar fe sufrimiento inmerecido redención',\n",
       " 'volver mississippi volved alabama volved carolina sur volved georgia volved luisiana volved suburbio ghetto ciudad norte saber modo u situación poder ir ser cambiar',\n",
       " 'hundar valle desesperación',\n",
       " 'aun así aunque ver delante dificultad hoy mañana amigo decir hoy todavía sueño',\n",
       " 'sueño profundamente enraizado sueño americano',\n",
       " 'sueño día nación poner pie realizar verdadero significado credo sostener verdad evidente mismo hombre ser creado igual',\n",
       " 'sueño día colina rojo georgia hijo esclavo hijo propietario esclavo capaz sentar él junto mesa fraternidad',\n",
       " 'sueño día incluso mississippi sofocante calor injusticia sofocante calor opresión transformar oasis libertad justicia',\n",
       " 'sueño cuatro hijo vivir día nación juzgado color piel sino reputación',\n",
       " 'sueño hoy',\n",
       " 'sueño día allá abajo alabama racista despiadado gobernador labio gotear palabra interposición anulación día justo allí alabamo niño negro niña negro poder dar él mano niño blanco niña blanco hermana hermano',\n",
       " 'sueño hoy',\n",
       " 'sueño día valle alzado todo colina montaña bajado lugar escarpado hacer llano lugar tortuoso enderezar gloria señor mostrar todo carne juntamente ver',\n",
       " 'este esperanza',\n",
       " 'este fe volver sur',\n",
       " 'fe capaz cortar montaña desesperación piedra esperanza',\n",
       " 'fe capaz transformar chirriante disonancia nación hermoso sinfonía fraternidad',\n",
       " 'fe capaz trabajar junto rezar junto luchar junto ir cárcel junto poner yo pie junto libertad saber día libre',\n",
       " 'este día este día hijo dio poder cantar nuevo significado tierra dulce tierra libertad canto',\n",
       " 'tierra padre muerto tierra orgullo peregrino cada ladera sonar libertad',\n",
       " 'si américa ir ser gran nación llegar ser verdad',\n",
       " 'así sonar libertad prodigioso cumbre colina new hampshire',\n",
       " 'sonar libertad enorme montaña nuevo york',\n",
       " 'sonar libertad elevado allegheny pennsylvania',\n",
       " 'sonar libertad rocoso cubierto nieve colorado',\n",
       " 'sonar libertad curva vertiente californio',\n",
       " 'sólo sonar libertad montaña piedra georgia',\n",
       " 'sonar libertad monte lookout tennesse e',\n",
       " 'sonar libertad cada colina cada topera mississippi cada ladera',\n",
       " 'sonar libertad',\n",
       " 'ocurrir permitir libertad sonar dejar sonar cada pueblo cada aldea cada cada ciudad poder acelerar llegada aquel día hijo dio hombre blanco hombre negro judío gentile protestante católico capaz juntar mano cantar palabra viejo espiritual negro fin libre',\n",
       " 'fin libre',\n",
       " 'gracia dio todopoderoso fin libre']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Implementing TF-IDF\n",
    "\n",
    "Now that the data is preprocessed, we can generate the **TF-IDF vectors** for each document in the corpus. These vectors will have a weight for each word, indicating its importance.\n",
    "\n",
    "- Each document is represented as a vector where the values represent the **TF-IDF score** for each word in the vocabulary.\n",
    "- Words that are common across the corpus will have lower weights, while unique or important words will have higher weights.\n",
    "\n",
    "### Advantages of TF-IDF:\n",
    "- **Captures Importance**: Words that are unique to specific documents are given more importance.\n",
    "- **Reduces Impact of Common Words**: High-frequency words across all documents are penalized.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create the TD-IDF model\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "td_idf = TfidfVectorizer(max_features=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = td_idf.fit_transform(sentences).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.361, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.495, 0],\n",
       "       [0, 0.604, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.395, 0.369, 0, ..., 0, 0, 0, 0, 0.286, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0.414, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.414, 0, 0, 0, 0, 0, 0, 0, 0.395, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.414, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0.402, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.402, 0, 0, 0, 0, 0, 0, 0, 0.383, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0.455, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.402, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0.505, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.505, 0, 0, 0, 0, 0, 0, 0, 0.481, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0.37, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.37, 0, 0, 0, 0, 0, 0, 0, 0.352, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0.419, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.391, 0.37, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0.548, 0.518, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.473, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.663, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.572, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0.472, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0.365, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0.235, 0, 0.279, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.261, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0.61, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0.401, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.748, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0.29, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.599, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.511, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0.345, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.73, 0, 0, 0, 0, 0.345, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.315, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0.507, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.543, 0, 0.437, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.411, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.392, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.823],\n",
       "       [0.491, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.491, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0.429, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0.51, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.429, 0, 0, 0, 0, 0, 0, 0.476, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0.391, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0.465, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.391, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0.418, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.439, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.418, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.566, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0.75, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0.324, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0.771, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.34, 0, 0],\n",
       "       [0, 0, 0, 0.613, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.573, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, 0, 0, 0.352, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.372, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.272, 0, 0, 0, 0, 0, 0.352, 0, 0, 0, 0, 0, 0, 0.399, 0, 0, 0, 0, 0],\n",
       "       [0, 0.565, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.825, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.269, 0, 0, 0, ..., 0, 0, 0, 0, 0.277, 0, 0, 0.383, 0, 0, 0, 0.261, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.383, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.237, 0, 0, 0, 0.249, 0, 0, 0, 0, 0, 0, 0, 0.198, 0.564, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.192, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.249],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.584, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.187, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.584, 0, 0.182, 0, 0, 0, 0, 0, 0, 0, 0, 0.267, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.4, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0.571, 0, 0, 0.389, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.661, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0.375, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.197, 0, 0, 0, 0, 0, 0.313, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.152, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.197],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.661, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.249, 0, 0, 0, 0, 0, 0, 0, 0.198, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.193, 0, 0, 0, 0, 0, 0, 0.565, 0, 0, 0, 0.264, 0, 0.283, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.707, 0.707, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.51, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.546, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.482, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.48, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.533, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.434, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.516, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.145, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.121, 0, 0, 0, ..., 0, 0.173, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.173, 0, 0, 0, 0, 0, 0, 0, 0, 0.161, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.268, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.237, 0.376, 0, 0, 0.501, ..., 0, 0, 0, 0, 0, 0, 0, 0.268, 0, 0, 0, 0, 0, 0, 0, 0, 0.501, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.378, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.276, 0, 0, 0, 0, 0, 0.756, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0.331, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0.513, 0.355, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.355, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0.581, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.581, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.449, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.449, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.788, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.788, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.788, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.377, 0, 0, 0, 0.516, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.788, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.839, 0, 0, 0, 0, 0, 0, 0, 0.264, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.204, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.788, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0.151, 0, 0, 0.672, 0, 0, 0.18, 0.151, 0, 0, 0.168, 0, 0, 0, 0, 0, 0, 0, 0.159, 0.126, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.245, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.586, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(edgeitems=30, linewidth=100000, \n",
    "    formatter=dict(float=lambda x: \"%.3g\" % x))\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Introducing N-Grams\n",
    "\n",
    "### What are N-Grams?\n",
    "\n",
    "**N-Grams** represent sequences of words (N refers to the number of words in a sequence). They help capture the relationship between consecutive words in a document, providing some context that is otherwise lost in models like Bag of Words and TF-IDF, which treat words independently.\n",
    "\n",
    "- **Unigrams**: Single words (same as Bag of Words).\n",
    "- **Bigrams**: Sequences of two consecutive words.\n",
    "- **Trigrams**: Sequences of three consecutive words.\n",
    "\n",
    "Using N-Grams helps capture phrases or combinations of words that carry more meaning together than individually.\n",
    "\n",
    "### N-Grams for Context:\n",
    "- **Bigrams** can capture pairs of words like \"machine learning\" or \"deep learning\".\n",
    "- **Trigrams** can capture phrases like \"natural language processing\".\n",
    "\n",
    "N-Grams are especially useful in tasks like sentiment analysis, document classification, or any task where word order or context matters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Combining TF-IDF with N-Grams\n",
    "\n",
    "By combining **TF-IDF** with **N-Grams**, we can capture both word importance and the contextual relationship between words. This provides a more powerful representation for downstream tasks like text classification or clustering.\n",
    "\n",
    "- **TF-IDF with Bigrams**: Assigns importance to word pairs based on their frequency and rarity across the corpus.\n",
    "- **TF-IDF with Trigrams**: Captures the importance of word triples, providing even more context.\n",
    "\n",
    "This combination helps in tasks where both word importance and context (word order) are crucial, such as document retrieval, sentiment analysis, or language modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_ngrams=TfidfVectorizer(max_features=100, ngram_range=(2,2))\n",
    "X_ngrams=tf_idf_ngrams.fit_transform(sentences).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'washington trabajo': np.int64(98),\n",
       " '28 agosto': np.int64(0),\n",
       " 'agosto 1963': np.int64(6),\n",
       " 'bajo cuyo': np.int64(21),\n",
       " 'acabar largo': np.int64(2),\n",
       " 'cien año': np.int64(56),\n",
       " 'año después': np.int64(19),\n",
       " 'después persona': np.int64(59),\n",
       " 'persona negro': np.int64(74),\n",
       " 'negro todavía': np.int64(72),\n",
       " 'cadena discriminación': np.int64(45),\n",
       " 'vivir isla': np.int64(86),\n",
       " 'así venir': np.int64(15),\n",
       " 'hoy aquí': np.int64(68),\n",
       " 'capital nación': np.int64(51),\n",
       " 'cobrar cheque': np.int64(57),\n",
       " 'ir ser': np.int64(69),\n",
       " 'hombre negro': np.int64(67),\n",
       " 'hombre blanco': np.int64(66),\n",
       " 'blanco garantizar': np.int64(25),\n",
       " 'búsqueda felicidad': np.int64(36),\n",
       " 'negar creer': np.int64(71),\n",
       " 'banco justicia': np.int64(23),\n",
       " 'bancario oportunidad': np.int64(22),\n",
       " 'urgencia momento': np.int64(82),\n",
       " 'dar él': np.int64(58),\n",
       " 'ahora tiempo': np.int64(9),\n",
       " 'tiempo hacer': np.int64(81),\n",
       " 'hijo dio': np.int64(65),\n",
       " 'ahora contento': np.int64(8),\n",
       " 'brusco despertar': np.int64(32),\n",
       " 'volver actividad': np.int64(92),\n",
       " 'actividad si': np.int64(5),\n",
       " 'brillante justicia': np.int64(31),\n",
       " 'acción equivocado': np.int64(3),\n",
       " 'busquemo saciar': np.int64(34),\n",
       " 'beber copa': np.int64(24),\n",
       " 'violencia físico': np.int64(84),\n",
       " 'yo desconfiar': np.int64(99),\n",
       " 'blanco hermano': np.int64(27),\n",
       " 'blanco presencia': np.int64(30),\n",
       " 'volver atrás': np.int64(93),\n",
       " 'poder satisfecho': np.int64(75),\n",
       " 'satisfecho mientras': np.int64(76),\n",
       " 'mientras persona': np.int64(70),\n",
       " 'víctima indecible': np.int64(97),\n",
       " 'brutalidad policía': np.int64(33),\n",
       " 'cargado fatiga': np.int64(52),\n",
       " 'autopista hotel': np.int64(18),\n",
       " 'básico persona': np.int64(35),\n",
       " 'votar persona': np.int64(96),\n",
       " 'nuevo york': np.int64(73),\n",
       " 'agua rectitud': np.int64(7),\n",
       " 'búsqueda libertad': np.int64(37),\n",
       " 'viento brutalidad': np.int64(83),\n",
       " 'volver mississippi': np.int64(94),\n",
       " 'volved alabama': np.int64(87),\n",
       " 'alabama volved': np.int64(11),\n",
       " 'volved carolina': np.int64(88),\n",
       " 'carolina sur': np.int64(54),\n",
       " 'volved georgia': np.int64(89),\n",
       " 'volved luisiana': np.int64(90),\n",
       " 'volved suburbio': np.int64(91),\n",
       " 'aun así': np.int64(16),\n",
       " 'aunque ver': np.int64(17),\n",
       " 'sueño día': np.int64(79),\n",
       " 'día nación': np.int64(61),\n",
       " 'capaz sentar': np.int64(48),\n",
       " 'sofocante calor': np.int64(77),\n",
       " 'calor injusticia': np.int64(46),\n",
       " 'calor opresión': np.int64(47),\n",
       " 'vivir día': np.int64(85),\n",
       " 'sueño hoy': np.int64(80),\n",
       " 'abajo alabama': np.int64(1),\n",
       " 'alabama racista': np.int64(10),\n",
       " 'alabamo niño': np.int64(12),\n",
       " 'blanco niña': np.int64(29),\n",
       " 'blanco hermana': np.int64(26),\n",
       " 'bajado lugar': np.int64(20),\n",
       " 'carne juntamente': np.int64(53),\n",
       " 'volver sur': np.int64(95),\n",
       " 'fe capaz': np.int64(63),\n",
       " 'capaz transformar': np.int64(50),\n",
       " 'capaz trabajar': np.int64(49),\n",
       " 'este día': np.int64(62),\n",
       " 'día hijo': np.int64(60),\n",
       " 'cada ladera': np.int64(42),\n",
       " 'sonar libertad': np.int64(78),\n",
       " 'allegheny pennsylvania': np.int64(14),\n",
       " 'cada colina': np.int64(41),\n",
       " 'cada topera': np.int64(44),\n",
       " 'cada pueblo': np.int64(43),\n",
       " 'cada aldea': np.int64(38),\n",
       " 'aldea cada': np.int64(13),\n",
       " 'cada cada': np.int64(39),\n",
       " 'cada ciudad': np.int64(40),\n",
       " 'acelerar llegada': np.int64(4),\n",
       " 'blanco hombre': np.int64(28),\n",
       " 'católico capaz': np.int64(55),\n",
       " 'fin libre': np.int64(64)}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_ngrams.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0.707, 0, 0, 0, 0, 0, 0.707, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.447, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0.507, 0, 0.345, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.492, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0.38, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.436, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0.337, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.54, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.447, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0.507, 0, 0.345, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.707, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.522, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.738, 0, 0, 0, 0, 0, 0, ..., 0, 0.675, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.738, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0.675, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.707, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0.662, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.75, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0.542, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.614, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0.563, 0, 0, 0, 0, 0, 0, 0, 0.826, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0.477, 0, 0, 0.477, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0.298, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.477, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.707, 0.707, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.644, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.61, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0.779, 0, 0.3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.738, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0.398, 0, 0, 0, 0, 0, 0, 0, 0, 0.398, 0, 0.398, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.398, 0, 0, 0.398, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.306, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.621, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.478, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0.574, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0.819, 0, 0, 0, 0, 0.574, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.842, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0.54, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0.356, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0.289, 0, 0, 0, 0, 0, 0, 0, 0, 0.289, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.289, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ngrams\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
